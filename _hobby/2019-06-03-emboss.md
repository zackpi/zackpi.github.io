---
title: Virtual Embossing Software
date: 2019-06-03 5:09
layout: hobbyproj
---

My friend Ed Ho makes paper art over on his ![youtube channel](https://www.youtube.com/channel/UCF81fbvHsdvkGg2WCNvGIJA) and we are currently roommates (summer '19). He's been working on a series of projects making embossings using layered cutouts of paper that he designs in Adobe Illustrator and cuts out either by hand with an Xacto knife or with his [Silhouette Portait](https://www.silhouetteamerica.com/shop/machines/portrait). The trick was he would make the 3d cavities out of the empty spaces in that paper, then he would push thicker paper into the negative space to leave an embossed positive on the surface. Check out one of his pieces [here](https://www.youtube.com/).

His overall project was to make a poster design and corresponding embossing for each of the ![Studio Ghibli](https://www.studioghibli.com.au/) films--My Neighbour Totoro, Spirited Away, etc. Each iteration of his design took over an hour to tweak, print, glue, and press. And he would often have to go through multiple iterations to perfect each design. And since there are 24 Ghibli films, I figured this was a job for Software Engineering&trade;!

I have a summer's worth of experience doing [computer graphics / image processing work](../work/waylens) for [Waylens](https://waylens.com/), so since I know my way around OpenCV I was able to put together a decent script that would simplify Ed's life and in his words, "Change the game" for his design workflow during this and other embossing projects.

The script accepts an image of his design and approximates what the final embossed paper would look like. It performs well enough that he can skip several laborious steps in the design process and just focus on the aesthetics. It also allows him to take risks and compare lots of different options because now there's little cost to try random changes, whereas before it would have wasted over an hour if he made a mistake in the design phase.

Here's some sample output for a [Totoro poster](https://edho-design.github.io) before we get into the code. The left is the layers that go into the program, the middle is the output of the program, and the right is the final version after pressing the paper through the mold. 

<img src="/assets/img/hobby/emboss/totoro_layers.png" alt="totoro layers" width="500">
<img src="/assets/img/hobby/emboss/totoro_virtual.png" alt="embossed virtual totoro" width="500">
<img src="/assets/img/hobby/emboss/totoro_final.jpg" alt="embossed paper totoro" width="500">

I wanted to make the program as simple to use as possible, so the input could just be a simple screenshot of his work during the design phase. However, this means that some information about the layers in the design would be missing. Even more troublesome, information about the edges in the image is also destroyed when moving from the vector to raster world. Luckily, Ed was already using the saturation of the color in a given layer to denote its depth to him visually (see the leftmost Totoro above). So the program can use this hint in the opposite direction to distinguish the different parts of the design by the saturation channel of the HSV image.

With that in mind, the first thing the code does is read in an image corresponding to the input from the command line and change its color space to HSV.

```python
img = cv2.imread(args.filename)
hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
h, s, v = cv2.split(hsv)
```

Now we're ready to start figuring out what saturation levels exist in the most prominent numbers and interpret those (with reasonable cutoffs) as the different layers of the image. First I collected a histogram of all the saturation values in the image. Then I used scipy's `find_peaks` function to locate the most frequently appearing values.

```python
val_count = [0]*256
rows, cols = s.shape
for i in range(rows):
  for j in range(cols):
    val_count[s[i,j]] += 1
val_count[0] = 0  # since I'm masking off the noisy regions aka setting them to 0
colors, _ = find_peaks(val_counts)
```

If I plot this right away I can visually make out the different peaks that correspond to the different layers in the image, and the program would probably work for this image with the right parameters plugged into `find_peaks`. But I'm not sure that this would work for every image and it's not clear what those parameters should be even for this one. Some more pre-processing will be necessary before applying `find_peaks`.

<img src="/assets/img/hobby/emboss/plot_linear.png" alt="plot of raw histogram data" width="500">

The plot shows that regions in the image have approximately exponentially decreasing areas. This fits a model of cartoony and simplified artwork, where there are large areas of solid color and some areas with more detail. This motivates taking the logarithm of the counts to make all of the peaks closer together so I can operate on them in parallel more effectively. Unfortunately, this magnifies the noise relative to the larger peaks.

<img src="/assets/img/hobby/emboss/plot_log_noisy.png" alt="plot of log noisy histogram data" width="500">

The next step is clearly to remove this noise. Since the noise is spread across the spectrum, it must not be coming from inside a solid region where the noise would be localized around a discrete saturation value. Instead, the noise exists mainly at the turbulent edges of these regions, where smoothing from Adobe Illustrator's rastering and artifacts from the screen capture's JPEG compression allow pixels to take on any value between those of the regions they border. 

In order to detect the edges, I will use a canny filter to find the places with the maximum gradient on the S channel. I chose the thresholding on the canny filter (0,50) to trigger on just about any edge since each layer is approximately a single value so there shouldn't really be any rogue curves in undesirable regions. I applied a Gaussian blur beforehand to smooth the high-frequency noise that occurs pixel-to-pixel and leave just the most important edges that occur between solid regions. I then used a dilated version of the detected edges to mask off the fuzzy pixels near the edges. To make the color counts as clear as possible I was finally able to eliminate them.

```python
# apply Canny filter
blur = cv2.GaussianBlur(s, (3,3), 0)
edge = cv2.Canny(blur, 0, 50)

# filter out noise at the edges
kernel = np.ones((3,3),np.uint8)
mask = cv2.dilate(edge, kernel, iterations=1)
filt = cv2.bitwise_and(cv2.bitwise_not(mask), v)
```

 The resulting plot is much more promising. However, after applying the mask, the smallest regions got even smaller and now their area is so small that the noise in that region of the colorspace is still significant.
<img src="/assets/img/hobby/emboss/plot_log_clean.png" alt="plot of log clean histogram data" width="500">

The final step to clean these peaks was to use one more assumption about the input image: that the levels are reasonably spaced in the color space. This justifies taking the z-score of each peak relative to a window around that saturation value to determine how significant its count is. Another trick was limiting the number of buckets to 128 or 64 since the peaks should be spaced far enough apart to be placed in different buckets, and any noise close to those values would get absorbed into the bucket instead of being its own peak. Both of these tricks led to a much cleaner plot, for which it was clear how to choose to parameters for `find_peaks`. I decided that if the height of the peak was greater than 1, meaning it was at least a standard deviation above the mean of the window around it in the color space, then the value was reasonably outlying and could be considered a peak. This rule yields the following peaks which correspond perfectly to the levels in the test image:

<img src="/assets/img/hobby/emboss/plot_norm.png" alt="plot of normalized histogram data" width="500">

<img src="/assets/img/hobby/emboss/noface_layers.png" alt="noface layers" width="500">
<img src="/assets/img/hobby/emboss/noface_virtual.png" alt="embossed virtual noface" width="500">


Finally, here is another example of the program output vs the final paper version for a [Princess Mononoke poster](https://edho-design.github.io):

<img src="/assets/img/hobby/emboss/mononoke_virtual.png" alt="embossed virtual mononoke" width="500">
<img src="/assets/img/hobby/emboss/mononoke_final.jpg" alt="embossed paper mononoke" width="500">
